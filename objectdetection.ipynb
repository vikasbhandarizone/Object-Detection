{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgUSjmliXn1v9Te2lHWgbY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vikasbhandarizone/Object-Detection/blob/main/objectdetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sGdikJ8i6s0D"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import cv2\n",
        "import PIL\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import io\n",
        "import html\n",
        "import time"
      ],
      "metadata": {
        "id": "QmIlsHED6yno"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# Clone the tensorflow models repository\n",
        "git clone --depth 1 https://github.com/tensorflow/models\n",
        "\n",
        "# API Installation\n",
        "sudo apt install -y protobuf-compiler\n",
        "cd models/research\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw_LIN_n65ej",
        "outputId": "f4f439fd-f22d-49cd-ff67-580051b38b40"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "protobuf-compiler is already the newest version (3.12.4-1ubuntu7.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Processing /content/models/research\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting avro-python3 (from object_detection==0.1)\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting apache-beam (from object_detection==0.1)\n",
            "  Downloading apache_beam-2.58.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (9.4.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (4.9.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (3.7.1)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (3.0.11)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (21.6.0)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.16.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.0.8)\n",
            "Collecting lvis (from object_detection==0.1)\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl.metadata (856 bytes)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.13.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.1.4)\n",
            "Collecting tf-models-official>=2.5.1 (from object_detection==0.1)\n",
            "  Downloading tf_models_official-2.17.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting tensorflow_io (from object_detection==0.1)\n",
            "  Downloading tensorflow_io-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (3.4.1)\n",
            "Collecting pyparsing==2.4.7 (from object_detection==0.1)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting sacrebleu<=2.2.0 (from object_detection==0.1)\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl.metadata (55 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.4/55.4 kB 3.0 MB/s eta 0:00:00\n",
            "Collecting portalocker (from sacrebleu<=2.2.0->object_detection==0.1)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (2024.5.15)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (1.26.4)\n",
            "Collecting colorama (from sacrebleu<=2.2.0->object_detection==0.1)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.137.0)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.2.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (1.6.17)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.10.0.84)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (6.0.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.1.99)\n",
            "Collecting seqeval (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 2.2 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.9.6)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.16.1)\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
            "Collecting tensorflow-text~=2.17.0 (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading tensorflow_text-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: tensorflow~=2.17.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.17.0)\n",
            "Requirement already satisfied: tf-keras>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2024.1)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim->object_detection==0.1) (1.4.0)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache-beam->object_detection==0.1)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 89.7/89.7 kB 5.4 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting orjson<4,>=3.9.7 (from apache-beam->object_detection==0.1)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.4/50.4 kB 2.1 MB/s eta 0:00:00\n",
            "Collecting dill<0.3.2,>=0.3.1.1 (from apache-beam->object_detection==0.1)\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 152.0/152.0 kB 9.1 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (2.2.1)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam->object_detection==0.1)\n",
            "  Downloading fastavro-1.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting fasteners<1.0,>=0.3 (from apache-beam->object_detection==0.1)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (1.64.1)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.5/43.5 kB 2.4 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (0.22.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.23.0)\n",
            "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (3.2.2)\n",
            "Collecting objsize<0.8.0,>=0.6.1 (from apache-beam->object_detection==0.1)\n",
            "  Downloading objsize-0.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (24.1)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading pymongo-4.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (1.24.0)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (3.20.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (1.4.2)\n",
            "Collecting redis<6,>=5.0.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading redis-5.0.8-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting requests!=2.32.*,<3.0.0,>=2.24.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.12.2)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: pyarrow<17.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (0.6)\n",
            "Collecting js2py<1,>=0.74 (from apache-beam->object_detection==0.1)\n",
            "  Downloading Js2Py-0.74-py3-none-any.whl.metadata (868 bytes)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (1.4.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (4.10.0.84)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object_detection==0.1) (1.2.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object_detection==0.1) (4.53.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io->object_detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (2.19.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (4.1.1)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam->object_detection==0.1)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache-beam->object_detection==0.1) (5.2)\n",
            "Collecting pyjsparser>=2.5.1 (from js2py<1,>=0.74->apache-beam->object_detection==0.1)\n",
            "  Downloading pyjsparser-2.7.1.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.20.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (2024.7.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (6.1.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam->object_detection==0.1)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis<6,>=5.0.0->apache-beam->object_detection==0.1) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests!=2.32.*,<3.0.0,>=2.24.0->apache-beam->object_detection==0.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests!=2.32.*,<3.0.0,>=2.24.0->apache-beam->object_detection==0.1) (3.7)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.17.0->tf-models-official>=2.5.1->object_detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.17.0->tf-models-official>=2.5.1->object_detection==0.1) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.17.0->tf-models-official>=2.5.1->object_detection==0.1) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.17.0->tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.17.0->tf-models-official>=2.5.1->object_detection==0.1) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.17.0->tf-models-official>=2.5.1->object_detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.17.0->tf-models-official>=2.5.1->object_detection==0.1) (71.0.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.17.0->tf-models-official>=2.5.1->object_detection==0.1) (2.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.17.0->tf-models-official>=2.5.1->object_detection==0.1) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.17.0->tf-models-official>=2.5.1->object_detection==0.1) (2.17.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object_detection==0.1) (0.1.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (0.6.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (4.9)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->object_detection==0.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->object_detection==0.1) (2.16.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official>=2.5.1->object_detection==0.1) (1.3.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (8.1.7)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (2.3)\n",
            "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.1.5)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.5.1)\n",
            "Requirement already satisfied: etils>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (1.7.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.17.0->tf-models-official>=2.5.1->object_detection==0.1) (0.44.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (2024.6.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (6.4.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (3.20.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (1.63.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (5.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->object_detection==0.1) (0.1.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object_detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object_detection==0.1) (3.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow~=2.17.0->tf-models-official>=2.5.1->object_detection==0.1) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow~=2.17.0->tf-models-official>=2.5.1->object_detection==0.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow~=2.17.0->tf-models-official>=2.5.1->object_detection==0.1) (3.0.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (1.3)\n",
            "Requirement already satisfied: docstring-parser~=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.16)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow~=2.17.0->tf-models-official>=2.5.1->object_detection==0.1) (2.1.5)\n",
            "Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.8/67.8 kB 2.4 MB/s eta 0:00:00\n",
            "Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 116.6/116.6 kB 6.7 MB/s eta 0:00:00\n",
            "Downloading tf_models_official-2.17.0-py2.py3-none-any.whl (2.9 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.9/2.9 MB 42.7 MB/s eta 0:00:00\n",
            "Downloading apache_beam-2.58.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.6/14.6 MB 61.4 MB/s eta 0:00:00\n",
            "Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Downloading tensorflow_io-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.6/49.6 MB 16.7 MB/s eta 0:00:00\n",
            "Downloading fastavro-1.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 72.2 MB/s eta 0:00:00\n",
            "Downloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Downloading Js2Py-0.74-py3-none-any.whl (1.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 31.1 MB/s eta 0:00:00\n",
            "Downloading objsize-0.7.0-py3-none-any.whl (11 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 141.9/141.9 kB 9.0 MB/s eta 0:00:00\n",
            "Downloading pymongo-4.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 51.8 MB/s eta 0:00:00\n",
            "Downloading redis-5.0.8-py3-none-any.whl (255 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 255.6/255.6 kB 14.2 MB/s eta 0:00:00\n",
            "Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.6/62.6 kB 3.5 MB/s eta 0:00:00\n",
            "Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 242.5/242.5 kB 14.7 MB/s eta 0:00:00\n",
            "Downloading tensorflow_text-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.2/5.2 MB 68.5 MB/s eta 0:00:00\n",
            "Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 87.4 MB/s eta 0:00:00\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 307.7/307.7 kB 15.0 MB/s eta 0:00:00\n",
            "Building wheels for collected packages: object_detection, avro-python3, crcmod, dill, hdfs, seqeval, pyjsparser, docopt\n",
            "  Building wheel for object_detection (setup.py): started\n",
            "  Building wheel for object_detection (setup.py): finished with status 'done'\n",
            "  Created wheel for object_detection: filename=object_detection-0.1-py3-none-any.whl size=1697358 sha256=1e7964dafd93a23452812f4b1bac47f9045ec0a91b72c18ca84b326eabc0194d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-s8kl474b/wheels/53/dd/70/2de274d6c443c69d367bd6a5606f95e5a6df61aacf1435ec0d\n",
            "  Building wheel for avro-python3 (setup.py): started\n",
            "  Building wheel for avro-python3 (setup.py): finished with status 'done'\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43994 sha256=bcc61fbb69df38fe3d0e953becac2970aa6e8084713bc5c1cc550cba8ac555d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/85/62/6cdd81c56f923946b401cecff38055b94c9b766927f7d8ca82\n",
            "  Building wheel for crcmod (setup.py): started\n",
            "  Building wheel for crcmod (setup.py): finished with status 'done'\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31406 sha256=2ea6db986a300553e405cc98072f8b039903c606b6983fdae73c6a48892bcdc3\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py): started\n",
            "  Building wheel for dill (setup.py): finished with status 'done'\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78542 sha256=c45ae22fdc6146709800eae46f4b329ab822ad238b95f259449f6829be4d24c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for hdfs (setup.py): started\n",
            "  Building wheel for hdfs (setup.py): finished with status 'done'\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34325 sha256=02dc4e037df979dd27bf5daf090921f9a7c6ee4267570da68733b993edbd2f31\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
            "  Building wheel for seqeval (setup.py): started\n",
            "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=792b21ccc324efd0f0d144e17e9bdcc3c8a16753687190e119d2904db415e29a\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "  Building wheel for pyjsparser (setup.py): started\n",
            "  Building wheel for pyjsparser (setup.py): finished with status 'done'\n",
            "  Created wheel for pyjsparser: filename=pyjsparser-2.7.1-py3-none-any.whl size=25983 sha256=5b2fe68e0d57e02d388c1e1a7af2c4a67f3bfc3f3bfadec033860899bad39097\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/81/26/5956478df303e2bf5a85a5df595bb307bd25948a4bab69f7c7\n",
            "  Building wheel for docopt (setup.py): started\n",
            "  Building wheel for docopt (setup.py): finished with status 'done'\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13704 sha256=3175225125a2e47c077cb481d1114149a5e17e84f028f9ae96db98e854d35693\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built object_detection avro-python3 crcmod dill hdfs seqeval pyjsparser docopt\n",
            "Installing collected packages: pyjsparser, docopt, crcmod, zstandard, tensorflow-model-optimization, tensorflow_io, requests, redis, pyparsing, portalocker, orjson, objsize, js2py, fasteners, fastavro, dnspython, dill, colorama, avro-python3, sacrebleu, pymongo, hdfs, seqeval, lvis, apache-beam, tensorflow-text, tf-models-official, object_detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.2\n",
            "    Uninstalling pyparsing-3.1.2:\n",
            "      Successfully uninstalled pyparsing-3.1.2\n",
            "Successfully installed apache-beam-2.58.1 avro-python3-1.10.2 colorama-0.4.6 crcmod-1.7 dill-0.3.1.1 dnspython-2.6.1 docopt-0.6.2 fastavro-1.9.5 fasteners-0.19 hdfs-2.7.3 js2py-0.74 lvis-0.5.3 object_detection-0.1 objsize-0.7.0 orjson-3.10.7 portalocker-2.10.1 pyjsparser-2.7.1 pymongo-4.8.0 pyparsing-2.4.7 redis-5.0.8 requests-2.31.0 sacrebleu-2.2.0 seqeval-1.2.2 tensorflow-model-optimization-0.8.0 tensorflow-text-2.17.0 tensorflow_io-0.37.1 tf-models-official-2.17.0 zstandard-0.23.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into 'models'...\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd models/research\n",
        "# Test the installation.\n",
        "''' If the output shows, [OK] then we're good to go'''\n",
        "!python object_detection/builders/model_builder_tf2_test.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZtIN20W68mP",
        "outputId": "fed06e7f-4222-4879-991c-72f765510498"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n",
            "2024-08-20 08:36:19.249072: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-20 08:36:19.272687: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-20 08:36:19.279429: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-20 08:36:20.816272: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/models/research/object_detection/builders/model_builder_tf2_test.py\", line 24, in <module>\n",
            "    from object_detection.builders import model_builder\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/object_detection/builders/model_builder.py\", line 26, in <module>\n",
            "    from object_detection.builders import hyperparams_builder\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/object_detection/builders/hyperparams_builder.py\", line 27, in <module>\n",
            "    from object_detection.core import freezable_sync_batch_norm\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/object_detection/core/freezable_sync_batch_norm.py\", line 20, in <module>\n",
            "    class FreezableSyncBatchNorm(tf.keras.layers.experimental.SyncBatchNormalization\n",
            "AttributeError: module 'keras._tf_keras.keras.layers' has no attribute 'experimental'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "ty3kdDrj7fzv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def record_video(filename='../../output.avi'):\n",
        "  js = Javascript(\"\"\"\n",
        "    async function recordVideo() {\n",
        "      // mashes together the advanced_outputs.ipynb function provided by Colab,\n",
        "      // a bunch of stuff from Stack overflow, and some sample code from:\n",
        "      // https://developer.mozilla.org/en-US/docs/Web/API/MediaStream_Recording_API\n",
        "\n",
        "      // Optional frames per second argument.\n",
        "      const options = { mimeType: \"video/webm; codecs=vp9\" };\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      const stopCapture = document.createElement(\"button\");\n",
        "      capture.textContent = \"Start Recording\";\n",
        "      capture.style.background = \"green\";\n",
        "      capture.style.color = \"white\";\n",
        "\n",
        "      stopCapture.textContent = \"Stop Recording\";\n",
        "      stopCapture.style.background = \"red\";\n",
        "      stopCapture.style.color = \"white\";\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      const recordingVid = document.createElement(\"video\");\n",
        "      video.style.display = 'block';\n",
        "\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "      // create a media recorder instance, which is an object\n",
        "      // that will let you record what you stream.\n",
        "      let recorder = new MediaRecorder(stream, options);\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      // Video is a media element.  This line here sets the object which serves\n",
        "      // as the source of the media associated with the HTMLMediaElement\n",
        "      // Here, we'll set it equal to the stream.\n",
        "      video.srcObject = stream;\n",
        "      // We're inside an async function, so this await will fire off the playing\n",
        "      // of a video. It returns a Promise which is resolved when playback has\n",
        "      // been successfully started. Since this is async, the function will be\n",
        "      // paused until this has started playing.\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "      // and now, just wait for the capture button to get clicked in order to\n",
        "      // start recording\n",
        "      await new Promise((resolve) => {\n",
        "        capture.onclick = resolve;\n",
        "      });\n",
        "      recorder.start();\n",
        "      capture.replaceWith(stopCapture);\n",
        "      // use a promise to tell it to stop recording\n",
        "      await new Promise((resolve) => stopCapture.onclick = resolve);\n",
        "      recorder.stop();\n",
        "\n",
        "      let recData = await new Promise((resolve) => recorder.ondataavailable = resolve);\n",
        "      let arrBuff = await recData.data.arrayBuffer();\n",
        "\n",
        "      // stop the stream and remove the video element\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "\n",
        "      let binaryString = \"\";\n",
        "      let bytes = new Uint8Array(arrBuff);\n",
        "      bytes.forEach((byte) => {\n",
        "        binaryString += String.fromCharCode(byte);\n",
        "      })\n",
        "      return btoa(binaryString);\n",
        "    }\n",
        "    \"\"\")\n",
        "  try:\n",
        "    display(js)\n",
        "    data = eval_js('recordVideo({})')\n",
        "    binary = b64decode(data)\n",
        "    with open(filename, \"wb\") as video_file:\n",
        "      video_file.write(binary)\n",
        "    print(\n",
        "        f\"Finished recording video. Saved binary under filename in current working directory: {filename}\"\n",
        "    )\n",
        "  except Exception as err:\n",
        "      # In case any exceptions arise\n",
        "      print(str(err))\n",
        "  return filename\n",
        "\n",
        "def play_video(video_path):\n",
        "  video_file = open(video_path, \"r+b\").read()\n",
        "  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
        "  #print(video_url)\n",
        "  HTML(f\"\"\"\"\"\")"
      ],
      "metadata": {
        "id": "hdcyWFwP7nxx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "\n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "\n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "\n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "\n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "\n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"Status:\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "\n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "\n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML =\n",
        "          '' +\n",
        "          'When finished, click here or on the video to stop this demo';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "\n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "\n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "\n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "\n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "\n",
        "      return {'create': preShow - preCreate,\n",
        "              'show': preCapture - preShow,\n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "\n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data\n",
        "\n",
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array) # numpy array into PIL image object\n",
        "  iobuf = io.BytesIO()\n",
        "\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes"
      ],
      "metadata": {
        "id": "NgbTxeBI7tZx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_inference_for_single_image(model, image, live_cam):\n",
        "\n",
        "    # convert image into numpy\n",
        "    image = np.asarray(image)\n",
        "    #print('Converted image into numpy type:', type(image))\n",
        "\n",
        "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "    input_tensor = tf.convert_to_tensor(image)\n",
        "    #print('Converted numpy into tensor format:', input_tensor)\n",
        "\n",
        "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "    input_tensor = input_tensor[tf.newaxis,...]\n",
        "\n",
        "    # Run inference\n",
        "    if not live_cam:\n",
        "      start_time = time.time()\n",
        "      output_dict = model(input_tensor)\n",
        "      end_time = time.time()\n",
        "      print(f\"Inference time: {np.ceil(end_time-start_time)} seconds per frame\")\n",
        "\n",
        "    output_dict = model(input_tensor)\n",
        "    num_detections = int(output_dict.pop('num_detections')) # 300\n",
        "\n",
        "    # All outputs are batches tensors.\n",
        "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "    # We're only interested in the first num_detections.\n",
        "\n",
        "    output_dict = {key: value[0, :num_detections].numpy()\n",
        "                   for key, value in output_dict.items()}\n",
        "\n",
        "    output_dict['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
        "\n",
        "    return output_dict\n",
        "\n",
        "def run_inference_video(model, video_path, live_cam):\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "  if cap.isOpened():\n",
        "      width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "      height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "      res=(int(width), int(height))\n",
        "\n",
        "      # save detected video\n",
        "      # Initialize our video writer\n",
        "      fourcc = cv2.VideoWriter_fourcc(*\"XVID\") #codec\n",
        "      out = cv2.VideoWriter('../../detected_output.avi', fourcc, 20.0, res)\n",
        "      frame = None\n",
        "\n",
        "      while True:\n",
        "          try:\n",
        "              is_success, image_np = cap.read()\n",
        "          except cv2.error:\n",
        "              continue\n",
        "\n",
        "          if not is_success:\n",
        "              break\n",
        "\n",
        "          # Actual detection.\n",
        "          output_dict = run_inference_for_single_image(model, image_np, live_cam)\n",
        "\n",
        "          # Visualization of the results of a detection.\n",
        "          viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "              image_np,\n",
        "              output_dict['detection_boxes'],\n",
        "              output_dict['detection_classes'],\n",
        "              output_dict['detection_scores'],\n",
        "              category_index,\n",
        "              instance_masks=output_dict.get('detection_masks_reframed', None),\n",
        "              use_normalized_coordinates=True,\n",
        "              line_thickness=8)\n",
        "\n",
        "          out.write(image_np)\n",
        "\n",
        "\n",
        "      out.release()\n",
        "\n",
        "      # OPTIONAL: show last image\n",
        "      if frame:\n",
        "        cv2_imshow(frame)\n",
        "\n",
        "  cap.release()\n",
        "\n",
        "def run_inference_in_anaconda(model):\n",
        "  \"\"\" Function for Inferencing live video in anaconda environment \"\"\"\n",
        "  cap = cv2.VideoCapture(0)\n",
        "  while cap.isOpened():\n",
        "      ret, image_np = cap.read()\n",
        "\n",
        "      # Actual detection.\n",
        "      output_dict = run_inference_for_single_image(model, image_np, None)\n",
        "\n",
        "      # Visualization of the results of a detection.\n",
        "      viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "          image_np,\n",
        "          output_dict['detection_boxes'],\n",
        "          output_dict['detection_classes'],\n",
        "          output_dict['detection_scores'],\n",
        "          category_index,\n",
        "          instance_masks=output_dict.get('detection_masks_reframed', None),\n",
        "          use_normalized_coordinates=True,\n",
        "          line_thickness=8)\n",
        "\n",
        "      cv2.imshow('object_detection', cv2.resize(image_np, (800, 600)))\n",
        "\n",
        "      if cv2.waitKey(1) == ord('q'):\n",
        "          writer.write(image_np)\n",
        "          writer.release()\n",
        "          cap.release()\n",
        "          cv2.destroyAllWindows()\n",
        "          break"
      ],
      "metadata": {
        "id": "HxoFmlqA7ymT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_LABELS = 'object_detection/data/mscoco_label_map.pbtxt'\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
        "\n",
        "model_handle = 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1'\n",
        "\n",
        "print('loading model...')\n",
        "hub_model = hub.load(model_handle)\n",
        "print('model loaded!')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06wBXI8Y7353",
        "outputId": "d47ba875-7504-4e4d-cbe0-7eb89857fc27"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model...\n",
            "model loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Inference on captured video\n",
        "video_path = '../../output.avi'\n",
        "run_inference_video(hub_model, video_path, live_cam=False)\n",
        "\n",
        "''' Download \"detected_output.avi\" video and play in your laptop video player '''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "NohStfgh764H",
        "outputId": "51407af4-ae42-4bef-8500-792f77e2be25"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Download \"detected_output.avi\" video and play in your laptop video player '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = None\n",
        "count = 0\n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # convert JS response to OpenCV Image\n",
        "    img = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    # Actual detection.\n",
        "    output_dict = run_inference_for_single_image(hub_model, img, live_cam=True)\n",
        "\n",
        "    # Visualization of the results of a detection.\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        img,\n",
        "        output_dict['detection_boxes'],\n",
        "        output_dict['detection_classes'],\n",
        "        output_dict['detection_scores'],\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=8)\n",
        "\n",
        "    # Convert OpenCV BGR format to RGB format\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Convert numpy image type to Base64 image byte string type\n",
        "    # for JavaScript Video object\n",
        "    bbox_bytes = bbox_to_bytes(img)\n",
        "\n",
        "    # update bbox so next frame gets new overlay\n",
        "    bbox = bbox_bytes\n"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/None": {
              "data": "",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "0"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "lPMy5_Wy8BqQ",
        "outputId": "9ea9f700-1623-45a2-c985-feca40e44cb2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "\n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "\n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "\n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "\n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"Status:\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "\n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "\n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML =\n",
              "          '' +\n",
              "          'When finished, click here or on the video to stop this demo';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 640; //video.videoWidth;\n",
              "      captureCanvas.height = 480; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "\n",
              "      return stream;\n",
              "    }\n",
              "    async function stream_frame(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "\n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "\n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "\n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "\n",
              "      return {'create': preShow - preCreate,\n",
              "              'show': preCapture - preShow,\n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_inference_in_anaconda(hub_model)\n"
      ],
      "metadata": {
        "id": "LcGbfbd18D-i"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1DtHydcM8YXg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}